# -*- coding: utf-8 -*-
"""Copy of Modul 3 - Binary Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/106YUsezD66BlVqzXxS_88EZaKZe8BeuO

# **Import Library**
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

"""# **Data Loading**"""

import pandas as pd

# Gantilah ID file dengan ID dari Google Drive URL
file_id = '19IfOP0QmCHccMu8A6B2fCUpFqZwCxuzO'

# Buat URL unduhan langsung
download_url = f'https://drive.google.com/uc?id={file_id}'

# Baca file CSV dari URL
data = pd.read_csv(download_url)

# Tampilkan DataFrame untuk memastikan telah dibaca dengan benar
data.head()

# Tampilkan informasi umum tentang dataset
print("\nInformasi dataset:")
data.info()

# Cek missing values
print("\nMissing values per fitur:")
print(data.isnull().sum())

# Hapus kolom 'RowNumber', 'CustomerId', dan 'Surname'
data = data.drop(columns=['RowNumber', 'CustomerId', 'Surname'])

# Tampilkan DataFrame untuk memastikan kolom telah dihapus
data.head()

"""# **EDA**"""

# Distribusi fitur numerik
num_features = data.select_dtypes(include=[np.number])
plt.figure(figsize=(14, 10))
for i, column in enumerate(num_features.columns, 1):
    plt.subplot(3, 4, i)
    sns.histplot(data[column], bins=30, kde=True, color='blue')
    plt.title(f'Distribusi {column}')
plt.tight_layout()
plt.show()

# Distribusi fitur kategorikal
cat_features = data.select_dtypes(include=[object])
plt.figure(figsize=(14, 8))
for i, column in enumerate(cat_features.columns, 1):
    plt.subplot(2, 4, i)
    sns.countplot(y=data[column], palette='viridis')
    plt.title(f'Distribusi {column}')
plt.tight_layout()
plt.show()

# Heatmap korelasi untuk fitur numerik
plt.figure(figsize=(12, 10))
correlation_matrix = num_features.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Heatmap Korelasi')
plt.show()

# Pairplot untuk fitur numerik
sns.pairplot(num_features)
plt.show()

# Visualisasi distribusi variabel target
plt.figure(figsize=(8, 4))
sns.countplot(x='Exited', data=data, palette='viridis')
plt.title('Distribusi Variabel Target (Exited)')
plt.show()

# Menganalisis hubungan antara fitur dan variabel target
plt.figure(figsize=(16, 12))

# # Fitur numerik vs Target
# for i, column in enumerate(num_features.columns, 1):
#     if column != 'Exited':
#         plt.subplot(3, 4, i)
#         sns.boxplot(x='Exited', y=column, data=data, palette='viridis')
#         plt.title(f'{column} vs Exited')

# plt.tight_layout()
# plt.show()

# Fitur kategorikal vs Target
plt.figure(figsize=(14, 10))
for i, column in enumerate(cat_features.columns, 1):
    if column != 'Exited':
        plt.subplot(2, 4, i)
        sns.countplot(y=column, hue='Exited', data=data, palette='viridis')
        plt.title(f'{column} vs Exited')

plt.tight_layout()
plt.show()

"""# **Label Encoder**"""

# Buat instance LabelEncoder
label_encoder = LabelEncoder()

# List kolom kategorikal yang perlu di-encode
categorical_columns = ['Geography', 'Gender']

# Encode kolom kategorikal
for column in categorical_columns:
    data[column] = label_encoder.fit_transform(data[column])

# Tampilkan DataFrame untuk memastikan encoding telah diterapkan
data.head()

"""# **Data Splitting**"""

# Buat instance MinMaxScaler
scaler = MinMaxScaler()

# Normalisasi semua kolom numerik
numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns
data[numeric_columns] = scaler.fit_transform(data[numeric_columns])

# Pisahkan fitur (X) dan target (y)
X = data.drop(columns=['Exited'])
y = data['Exited']

# Split data menjadi set pelatihan dan set uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Tampilkan bentuk set pelatihan dan set uji untuk memastikan split
print(f"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}")

"""# **Model Deployment**"""

# Part 1: Model Training
# Train each classifier separately
knn = KNeighborsClassifier().fit(X_train, y_train)
dt = DecisionTreeClassifier().fit(X_train, y_train)
rf = RandomForestClassifier().fit(X_train, y_train)
svm = SVC().fit(X_train, y_train)
nb = GaussianNB().fit(X_train, y_train)

print("Model training selesai.")

"""# **Model Evaluation**

## **KNN**
"""

# K-Nearest Neighbors (KNN)
y_pred_knn = knn.predict(X_test)
cm_knn = confusion_matrix(y_test, y_pred_knn)
tn, fp, fn, tp = cm_knn.ravel()
print("==== KNN Classifier ====")
print("Confusion Matrix:")
print(cm_knn)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_knn):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_knn):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_knn):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('KNN Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## **Decision Tree**"""

y_pred_dt = dt.predict(X_test)
cm_dt = confusion_matrix(y_test, y_pred_dt)
tn, fp, fn, tp = cm_dt.ravel()
print("==== Decision Tree Classifier ====")
print("Confusion Matrix:")
print(cm_dt)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_dt):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_dt):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_dt):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Decision Tree Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## **Random Forest**"""

# Random Forest
y_pred_rf = rf.predict(X_test)
cm_rf = confusion_matrix(y_test, y_pred_rf)
tn, fp, fn, tp = cm_rf.ravel()
print("==== Random Forest Classifier ====")
print("Confusion Matrix:")
print(cm_rf)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_rf):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_rf):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_rf):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Random Forest Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## **Support Vector Machine (SVM)**"""

# Support Vector Machine (SVM)
y_pred_svm = svm.predict(X_test)
cm_svm = confusion_matrix(y_test, y_pred_svm)
tn, fp, fn, tp = cm_svm.ravel()
print("==== SVM Classifier ====")
print("Confusion Matrix:")
print(cm_svm)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_svm):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_svm):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_svm):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('SVM Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## **Naive Bayes**"""

# Naive Bayes
y_pred_nb = nb.predict(X_test)
cm_nb = confusion_matrix(y_test, y_pred_nb)
tn, fp, fn, tp = cm_nb.ravel()
print("==== Naive Bayes Classifier ====")
print("Confusion Matrix:")
print(cm_nb)
print(f"True Positive (TP): {tp}")
print(f"False Positive (FP): {fp}")
print(f"False Negative (FN): {fn}")
print(f"True Negative (TN): {tn}")
print(f"Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_nb):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_nb):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_nb):.4f}")
print("\n" + "-"*40 + "\n")

plt.figure(figsize=(5, 4))
sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Naive Bayes Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""# **Rangkuman Hasil**"""

# Function to evaluate and return results as a dictionary
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    results = {
        'Confusion Matrix': cm,
        'True Positive (TP)': tp,
        'False Positive (FP)': fp,
        'False Negative (FN)': fn,
        'True Negative (TN)': tn,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1-Score': f1_score(y_test, y_pred)
    }
    return results

# Evaluate each model and collect results
results = {
    'K-Nearest Neighbors (KNN)': evaluate_model(knn, X_test, y_test),
    'Decision Tree (DT)': evaluate_model(dt, X_test, y_test),
    'Random Forest (RF)': evaluate_model(rf, X_test, y_test),
    'Support Vector Machine (SVM)': evaluate_model(svm, X_test, y_test),
    'Naive Bayes (NB)': evaluate_model(nb, X_test, y_test)
}

# Create a DataFrame to summarize results
summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])

# Populate the DataFrame with results
rows = []
for model_name, metrics in results.items():
    rows.append({
        'Model': model_name,
        'Accuracy': metrics['Accuracy'],
        'Precision': metrics['Precision'],
        'Recall': metrics['Recall'],
        'F1-Score': metrics['F1-Score']
    })

# Convert list of dictionaries to DataFrame
summary_df = pd.DataFrame(rows)

# Display the summary DataFrame
print(summary_df)

"""# **Analisis Hasil Evaluasi Model**

Berdasarkan data evaluasi yang diperbarui, berikut adalah analisis untuk masing-masing model dengan mempertimbangkan metrik Accuracy, Precision, Recall, dan F1-Score:

### **Analisis Hasil Evaluasi Model**

1. **K-Nearest Neighbors (KNN)**
   - **Accuracy**: 82.40%
   - **Precision**: 59.53%
   - **Recall**: 32.57%
   - **F1-Score**: 42.11%

   **Analisis**: KNN memiliki akurasi yang baik (82.40%). Precision-nya (59.53%) menunjukkan bahwa model cukup baik dalam mengidentifikasi kasus positif yang sebenarnya. Namun, recall-nya (32.57%) menunjukkan bahwa model ini kurang efektif dalam menangkap semua kasus positif yang ada. F1-Score 42.11% mencerminkan trade-off antara precision dan recall.

2. **Decision Tree (DT)**
   - **Accuracy**: 78.50%
   - **Precision**: 45.93%
   - **Recall**: 53.18%
   - **F1-Score**: 49.29%

   **Analisis**: Decision Tree memiliki akurasi yang sedikit lebih rendah (78.50%) dibandingkan KNN. Precision-nya (45.93%) lebih rendah daripada beberapa model lain, tetapi recall-nya (53.18%) lebih baik, menunjukkan bahwa model ini lebih efektif dalam menangkap kasus positif. F1-Score 49.29% menunjukkan performa yang seimbang antara precision dan recall.

3. **Random Forest (RF)**
   - **Accuracy**: 86.75%
   - **Precision**: 76.89%
   - **Recall**: 46.56%
   - **F1-Score**: 58.00%

   **Analisis**: Random Forest menunjukkan performa terbaik di antara semua model dengan akurasi tertinggi (86.75%). Precision-nya (76.89%) juga sangat baik, menunjukkan bahwa model ini sangat akurat dalam memprediksi kasus positif. Recall-nya (46.56%) masih perlu ditingkatkan, tetapi F1-Score 58.00% menunjukkan trade-off yang baik antara precision dan recall.

4. **Support Vector Machine (SVM)**
   - **Accuracy**: 85.30%
   - **Precision**: 82.78%
   - **Recall**: 31.81%
   - **F1-Score**: 45.96%

   **Analisis**: SVM memiliki akurasi yang tinggi (85.30%) dan precision yang sangat baik (82.78%). Namun, recall-nya yang rendah (31.81%) menunjukkan bahwa model ini cenderung melewatkan banyak kasus positif. F1-Score 45.96% mencerminkan trade-off antara precision yang tinggi dan recall yang rendah.

5. **Naive Bayes (NB)**
   - **Accuracy**: 82.85%
   - **Precision**: 68.12%
   - **Recall**: 23.92%
   - **F1-Score**: 35.40%

   **Analisis**: Naive Bayes memiliki akurasi yang kompetitif (82.85%) dan precision yang cukup baik (68.12%). Namun, recall-nya yang rendah (23.92%) menunjukkan bahwa model ini kurang efektif dalam menangkap kasus positif. F1-Score 35.40% menunjukkan bahwa model ini cenderung memberikan hasil yang lebih baik dalam hal precision tetapi kurang baik dalam hal recall.

### **Kesimpulan:**
- **Random Forest** adalah model dengan **akurasi tertinggi** (86.75%) dan **precision yang sangat baik** (76.89%). Meskipun recall-nya tidak setinggi model lain, F1-Score-nya yang tertinggi (58.00%) menunjukkan keseimbangan yang baik antara precision dan recall. Ini menjadikannya pilihan yang sangat baik untuk banyak aplikasi.

- **SVM** menunjukkan **precision yang sangat tinggi** (82.78%) tetapi dengan **recall yang sangat rendah** (31.81%), yang berarti model ini lebih selektif dalam mengidentifikasi kasus positif.

- **Decision Tree** memberikan performa yang seimbang dengan **recall yang lebih tinggi** (53.18%) dibandingkan dengan beberapa model lain, tetapi dengan akurasi dan precision yang lebih rendah.

- **KNN** memiliki performa yang baik secara keseluruhan tetapi memiliki trade-off antara precision dan recall yang harus dipertimbangkan.

- **Naive Bayes** memiliki precision yang baik tetapi recall yang rendah, membuatnya kurang ideal jika menangkap semua kasus positif sangat penting.

**Rekomendasi**: Jika tujuan utama adalah akurasi dan precision, **Random Forest** adalah pilihan terbaik. Jika recall sangat penting, maka model seperti **Decision Tree** bisa dipertimbangkan lebih lanjut.
"""